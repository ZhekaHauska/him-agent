_type_: stp_experiment.tm_sequence_learning
project: stp.new_tm.test_text
log: True    # wandb logging, use 'dry' for dummy do-nothing logging to test metrics collection

seed: 1313
reset_tm: False
iterate:
  _base_: iterate_setups.small_10k

log_schedule:
  # add emit dict to skip logging steps/seq_started
  epoch: 1
  repeat: 5

model:
  global_config: ???
  external:
    - step
    - step_finished
    - sequence_id
    - sequence_finished
    - epoch
    - epoch_finished
    - tracking_enabled
    - learn
  pipeline:
    - predict input w/ prior belief:
      - TM.predict()
      - TM.predicted_cells.sdr -> decoder.feedforward.sdr
      - decoder.decode()
      - decoder.output.sdr -> input_prediction.sdr
    - embed input:
#      - input.sdr -> SE.feedforward.sdr
#      - SE.compute()
#      - SE.output.sdr -> embed_input.sdr
      - input.sdr -> embed_input.sdr
    - compute TM:
      - embed_input.sdr -> TM.feedforward.sdr
      - TM.compute()
      - TM.compare_with_prediction()
      - TM.active_cells.sdr -> TM.state.sdr
    - learn decoder:
      - embed_input.sdr -> decoder.feedback.sdr
      - decoder.learn()
    - predict input w/ posterior belief:
      - TM.state.sdr -> decoder.feedforward.sdr
      - decoder.decode()
      - decoder.output.sdr -> input_posterior_prediction.sdr

#  track_smoothing:
  track:
#    - name: input_all
#      tracker: trackers.sdr
#      on:
#        sequence_started: epoch
#        sdr_updated: input.sdr
#        sequence_finished: epoch_finished
    - name: state_L1.prediction
      tracker: trackers.sdr_prediction
      on:
        sequence_started: epoch
        sdr_predicted: TM.predicted_cells.sdr
        sdr_observed: TM.active_cells.sdr
        sequence_finished: epoch_finished
    - name: state_L2.prediction
      tracker: trackers.sdr_prediction
      on:
        sequence_started: epoch
        sdr_predicted: TM2.predicted_cells.sdr
        sdr_observed: TM2.active_cells.sdr
        sequence_finished: epoch_finished

    - name: input.prediction.prior
      tracker: trackers.sdr_prediction
      on:
        sequence_started: epoch
        sdr_predicted: input_prediction.sdr
        sdr_observed: embed_input.sdr
        sequence_finished: epoch_finished

    - name: input.prediction.posterior
      tracker: trackers.sdr_prediction
      on:
        sequence_started: epoch
        sdr_predicted: input_posterior_prediction.sdr
        sdr_observed: embed_input.sdr
        sequence_finished: epoch_finished
#    - name: input.prediction.prior.sdr
#      tracker: trackers.sdr
#      on:
#        sequence_started: epoch
#        sdr_updated: input_prediction.sdr
#        sequence_finished: epoch_finished
#    - name: input.prediction.posterior.sdr
#      tracker: trackers.sdr
#      on:
#        sequence_started: epoch
#        sdr_updated: input_posterior_prediction.sdr
#        sequence_finished: epoch_finished

track_streams:
  input.sdr:
    - cross.online.el
  SE.output.sdr:
    - cross.online.el
  TM.predicted_cells.sdr:
    - cross.online.el
  TM2.predicted_cells.sdr:
    - cross.online.el
  input_prediction.sdr:
    - cross.online.el
  input_posterior_prediction.sdr:
    - cross.online.el

diff_stats:
  online_el:
    - input.sdr/epoch/sim_mx_on_el
    - SE.output.sdr/epoch/sim_mx_on_el
    - TM.predicted_cells.sdr/epoch/sim_mx_on_el
    - TM2.predicted_cells.sdr/epoch/sim_mx_on_el
    - input_prediction.sdr/epoch/sim_mx_on_el
    - input_posterior_prediction.sdr/epoch/sim_mx_on_el

data: datas.text_sequences

datas:
  synthetic_sequences:
    _base_: $_base.dataset.synthetic_sequences.general
    alphabet_size: 200
    encoder:
      _base_: $_base.encoder.random.fixed_sds
      sds: [ 600, 18 ]
  dvc_sequences:
    _base_: $_base.dataset.dvc_sequences
    sequential: True
  code_sequences:
    _base_: $_base.dataset.text_sequences
    encoder:
      _base_: $_base.encoder.random.fixed_sds
      sds: [ 600, 18 ]
    sequential: True
  text_sequences:
    _base_: $_base.dataset.text_sequences
    filepath: ~/data/text/text8.txt
    max_size_hint: 1_000_000
    encoder:
      _base_: $_base.encoder.random.fixed_sds
      sds: [ 200, 10 ]
    sequential: True


models:
  +SE_DVS+SE+SA+AA: $_base.models.+SE_DVS+SE+SA+AA
  +SE_DVS+SE+AA: $_base.models.+SE_DVS+SE+AA
  +SE_DVS+SE: $_base.models.+SE_DVS+SE

  # use winners instead of predicted cells
  +SE+SA+AA|W: $_base.models.+SE+SA+AA|W
  +SE+AA|W: $_base.models.+SE+AA|W

  +SE+SA+AA: $_base.models.+SE+SA+AA
  +SE+AA: $_base.models.+SE+AA
  +AA: $_base.models.+AA
  +SE: $_base.models.+SE

  LSTM+SE_DVS+SE: $_base.models.LSTM+SE_DVS+SE
  LSTM: $_base.models.LSTM

  Baseline TM: $_base.models_new.Baseline TM

  STM1:
    - predict input w/ prior belief:
        - TM.predict()
        - TM.predicted_cells.sdr -> decoder.feedforward.sdr
        - decoder.decode()
        - decoder.output.sdr -> input_prediction.sdr
    - embed input:
#        - input.sdr -> SE.feedforward.sdr
#        - SE.compute()
#        - SE.output.sdr -> embed_input.sdr
        - input.sdr -> embed_input.sdr
    - compute TM:
        - embed_input.sdr -> TM.feedforward.sdr
        - TM.compute()
        - TM.compare_with_prediction()
        - TM.active_cells.sdr -> TM.state.sdr
    - learn decoder:
        - embed_input.sdr -> decoder.feedback.sdr
        - decoder.learn()
    - predict input w/ posterior belief:
        - TM.state.sdr -> decoder.feedforward.sdr
        - decoder.decode()
        - decoder.output.sdr -> input_posterior_prediction.sdr

  STM2:
    - predict input w/ prior belief:
        - TM2.predict()
        - TM.predict()
        - TM.predicted_cells.sdr -> decoder.feedforward.sdr
        - decoder.decode()
        - decoder.output.sdr -> input_prediction.sdr
    - embed input:
        - input.sdr -> embed_input.sdr
    - compute TM^1:
        - embed_input.sdr -> TM.feedforward.sdr
        - TM.compute()
        - TM.compare_with_prediction()
        - TM.active_cells.sdr -> TM.state.sdr
    - compute TM^2:
        - TM.active_cells.sdr -> TM2.feedforward.sdr
        - TM2.compute()
        - TM2.compare_with_prediction()
        - TM2.active_cells.sdr -> TM2.state.sdr
    - learn decoder:
        - embed_input.sdr -> decoder.feedback.sdr
        - decoder.learn()
    - predict input w/ posterior belief:
        - TM.state.sdr -> decoder.feedforward.sdr
        - decoder.decode()
        - decoder.output.sdr -> input_posterior_prediction.sdr

SE:
  sp:
    _base_: $_base.spatial_pooler.default
#    _type_: sp.vectorized
    _type_: sp.float
#    _type_: sp.sdrr
    initial_rf_to_input_ratio: 12.0
    target_rf_to_input_ratio: 0.5
    learning_rate: 0.02
    newborn_pruning_cycle: 3.0
    newborn_pruning_stages: 20
    newborn_pruning_mode: powerlaw
    prune_grow_cycle: 100.0
    adapt_to_ff_sparsity: False
    boosting_k: 0.5
  stp:
    _base_: $_base.spatial_temporal_pooler.default
    max_pooling_window: 4
    reset_potential_on_activation: True
    initial_rf_to_input_ratio: 8.0
    max_rf_to_input_ratio: 1.5
    learning_rate: 0.001
    global_inhibition_strength: 0.2
    newborn_pruning_cycle: 2.0
    newborn_pruning_stages: 10
    prune_grow_cycle: 10.0
    adapt_to_ff_sparsity: False

TM:
  general_feedback_tm:
    _base_: $_base.temporal_memory.general_feedback_tm
    cells_per_column: 12
    activation_threshold_basal: .9
    learning_threshold_basal: .7
    max_synapses_per_segment_basal: 2.1
    max_segments_per_cell_basal: 16
  tm:
    _base_: $_base.temporal_memory.default
    cells_per_column: 8
    activation_threshold_basal: .9
    learning_threshold_basal: .7
    permanence_increment_basal: 0.1
    permanence_decrement_basal: 0.012
    predicted_segment_decrement_basal: 0.004
    max_synapses_per_segment_basal: 2.1
    max_segments_per_cell_basal: 16
  tm_new:
    _base_: $_base.spatial_pooler.default
#    _type_: sp.vectorized
    _type_: sp.float
#    _type_: sp.sdrr
    initial_max_rf_sparsity: 0.5
    target_rf_to_input_ratio: 2.0
    learning_rate: 0.02
    newborn_pruning_cycle: 3.0
    newborn_pruning_stages: 20
    newborn_pruning_mode: powerlaw
    prune_grow_cycle: 100.0
    adapt_to_ff_sparsity: False
    boosting_k: 0.5
#    output_mode: binary
  lstm:
    _type_: tm.lstm
    seed: ???
    input_size: ???
    hidden_size: 400
    lr: 0.002

AA:
  general_feedback_tm:
    _base_: $_base.temporal_memory.general_feedback_tm
    cells_per_column: 1
    activation_threshold_basal: .8
    learning_threshold_basal: .6
    max_synapses_per_segment_basal: 4.4
    max_segments_per_cell_basal: 32
  tm:
    _base_: $_base.temporal_memory.default
    cells_per_column: 1
    permanence_increment_basal: 0.1
    permanence_decrement_basal: 0.012
    predicted_segment_decrement_basal: 0.006
    activation_threshold_basal: .8
    learning_threshold_basal: .6
#    max_synapses_per_segment_basal: 4.2
#    max_segments_per_cell_basal: 32
    max_synapses_per_segment_basal: 1.5
    max_segments_per_cell_basal: 16

SA:
  sp:
    _base_: $_base.spatial_pooler.default
#    _type_: sp.vectorized
    _type_: sp.float
#    _type_: sp.sdrr
    initial_max_rf_sparsity: 0.33
    initial_rf_to_input_ratio: 60.0
    target_rf_to_input_ratio: 0.4
    learning_rate: 0.005
    newborn_pruning_cycle: 6.0
    newborn_pruning_stages: 16
    newborn_pruning_mode: powerlaw
    prune_grow_cycle: 100.0
    adapt_to_ff_sparsity: False
    boosting_k: 0.4
  stp:
    _base_: $_base.spatial_temporal_pooler.default
    initial_rf_to_input_ratio: 4.0  #12?
    max_rf_to_input_ratio: 2.0
    learning_rate: 0.02
    global_inhibition_strength: 0.2
    newborn_pruning_cycle: 1.0
    newborn_pruning_stages: 4
    prune_grow_cycle: 10.0
    adapt_to_ff_sparsity: False

SE_DVS:
  sp:
    _base_: $_base.spatial_pooler.default
    initial_rf_to_input_ratio: 8.0
    target_max_rf_sparsity: 1.5
    learning_rate: 0.001
    newborn_pruning_cycle: 2.5
    newborn_pruning_stages: 20
    prune_grow_cycle: 100.0
    adapt_to_ff_sparsity: False
  stp:
    _base_: $_base.spatial_temporal_pooler.default
    max_pooling_window: 4
    reset_potential_on_activation: True
    initial_rf_to_input_ratio: 8.0
    max_rf_to_input_ratio: 1.5
    learning_rate: 0.001
    global_inhibition_strength: 0.2
    newborn_pruning_cycle: 2.0
    newborn_pruning_stages: 10
    prune_grow_cycle: 10.0
    adapt_to_ff_sparsity: False

blocks:
  concat:
    _type_: block.concatenator
  decoder:
    _type_: block.decoder
    decoder:
      _base_: $_base.decoder.mlp
  SE:
    _type_: block.sp
    _base_: $_base.blocks.sp_like
    output_sds: [600, 18]
    sp:
      _base_: SE.sp
  SA:
    _type_: block.sp
    _base_: $_base.blocks.sp_like
    sp:
      _base_: SA.sp
  TM:
    _type_: block.tm
    _base_: $_base.blocks.tm_like
    tm:
      _base_: TM.tm
  TM2:
    _type_: block.tm
    _base_: $_base.blocks.tm_like
    tm:
      _base_: TM.tm
  AA:
    _type_: block.tm
    _base_: $_base.blocks.tm_like
    tm:
      _base_: AA.tm
  SE_DVS:
    _type_: block.sp
    _base_: $_base.blocks.sp_like
    output_sds: [1200, 0.04]
    sp:
      _base_: SE_DVS.sp
      initial_rf_to_input_ratio: 5.0
      target_max_rf_sparsity: 0.4
      adapt_to_ff_sparsity: True
      learning_rate: 0.002
      newborn_pruning_cycle: 2.5
      boosting_k: 0.25

stats_and_metrics:
  mae_normalization: no
  symmetrical_similarity: False
  distribution_metrics: pmf
  online_similarity_decay: 1.
  pmf_decay: 1.
  loss_normalization: False
  loss_layer_discount: 0.75

iterate_setups:
  small_10k:
    epochs: 10
    resample_frequency: 1
    sequences: [10, 1]
    elements: 100
  default_100k:
    epochs: 50
    resample_frequency: 1
    sequences: [10, 1]
    elements: 200
  default_5x20k:
    epochs: 50
    resample_frequency: 5
    sequences: [10, 1]
    elements: 200
  large_400k:
    epochs: 100
    resample_frequency: 1
    sequences: [10, 1]
    elements: 400
  large_5x80k:
    epochs: 100
    resample_frequency: 5
    sequences: [10, 1]
    elements: 400

trackers:
  sdr:
    _type_: tracker.sdr
    on: ???
  tm:
    _type_: tracker.tm
    on: ???
  sdr_prediction:
    _type_: tracker.sdr_prediction
    on: ???

wandb_init:
  _base_: $_base.wandb_init

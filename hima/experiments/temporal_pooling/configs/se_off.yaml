_type_: stp_experiment.se_offline
project: stp.se_offline_debug
log: True    # wandb logging, use 'dry' for dummy do-nothing logging to test metrics collection

seed: 42
setup: setups.binary_basic_sp
debug: False

train:
  n_epochs: 5
  batch_size: 64
test:
  eval_first: 3
  eval_schedule: 5
  n_epochs: 20
  noise: 0.0

classifier:
  classification: ???
  layers: ???
#  learning_rate: 0.0003
  learning_rate: 0.003
  collect_losses: 1
  symexp_logits: ???

sp:
  htm_sp:
    _type_: sp.htm
    seed: ???
    feedforward_sds: ???
    output_sds: ???
#    potential_synapses_ratio: 0.05
    potential_synapses_ratio: 0.1
#    potential_synapses_ratio: 0.25
#    potential_synapses_ratio: 1.0
    synapse_permanence_deltas: [0.14, 0.02]
    connected_permanence_threshold: 0.5
    boost_strength: 7.0
    boost_sliding_window: 1_500
    expected_normal_overlap_frequency: 0.2
    min_activation_threshold: 6

  soft_hebb:
    _type_: sp.soft_hebb
    seed: ???
    feedforward_sds: ???
    output_sds: ???
    init_radius: 20.0
    learning_rate: 0.025
    adaptive_lr: True
    normalize_dw: True
    beta: 200.0
    beta_lr: 0.0
    threshold: 0.001

  soft_hebb_ext:
    _base_: sp.soft_hebb
    init_radius: 20.0
    weights_bias: 0.001
    learning_rate: 0.025
    adaptive_lr: True
    normalize_dw: False
    beta: 200.0
    beta_lr: 0.002
    threshold: 0.001
    output_extra: 1.0
    min_active_mass: 0.75
    min_mass: 0.92
    bias_boosting: True
    negative_hebbian: 'no'
    filter_output: 'hard'
    normalize_output: 'no'

  krotov:
    _type_: sp.krotov
    seed: ???
    feedforward_sds: ???
    output_sds: ???
    init_radius: 10.0
    learning_rate: 0.01
    lebesgue_p: 3
    neg_hebb_delta: 0.4
    repu_n: 4.5

  krotov_adaptive:
    _base_: sp.krotov
    adaptive_lr: True
    weights_bias: 0.001

  gse:
    _type_: sp.gse
    seed: ???
    feedforward_sds: ???
    output_sds: ???
    adapt_to_ff_sparsity: True

    normalize_input_p: 0.0
    # no | subtract_avg | subtract_avg_and_clip
    filter_input_policy: no
    # weights norm [should be compatible with learning policy, i.e.
    #   p = 1 for linear and p >= 2 for krotov]
    lebesgue_p: 1.0
    init_radius: 20.0
    weights_distribution: normal
    inhibitory_ratio: 0.12

    # Weights power for matching [should be compatible with learning policy, i.e.
    #   lebesgue_p - 1 for krotov (use ... to make it auto-induced), and
    #   we allow any p for linear policy (however, only p = 1 is the most natural)]
    # ... | <power>
    match_p: ...
    # no | additive | multiplicative
    boosting_policy: multiplicative
    # powerlaw | exponential
    activation_policy: powerlaw
    beta: 1.0
    beta_lr: 0.0
    soft_extra: 1.0
    # with respect to top K against second top K
    beta_active_mass: [0.75, 0.94]

    normalize_output: False
    output_extra: 0.5

    # linear | krotov
    learning_policy: linear
    learning_rate: 0.01
    adaptive_lr: True
    # M | [M, Q]: M - hebb, Q - anti-hebb; ints or floats â€” absolute or relative to K
    learning_set: [1.0, 0.4]
    anti_hebb_scale: 1.0
    persistent_signs: True
    normalize_dw: False

    pruning:
      n_stages: 25
      cycle: 200.0
      # linear | powerlaw
      mode: powerlaw
      target_rf_sparsity: 0.5

  se:
    _type_: sp.se
    seed: ???
    feedforward_sds: ???
    adapt_to_ff_sparsity: True
    output_sds: ???
    init_radius: 10.0
    inhibitory: 0.12
    # linear | sqrt
    match_policy: sqrt
    learning_rate: 0.01
    # pair | all
    learning_set: all
    neg_hebb_delta: 0.4
    pruning:
      n_stages: 20
      cycle: 100.0
      mode: linear
      target_rf_sparsity: 0.35

  float_sp:
    _base_: _common_base
    _type_: sp.float
    output_sds: ???

  sng_sp:
    _type_: sp.layer_bckp
    seed: ???
    # input
    feedforward_sds: ???

    # input
    target_max_rf_sparsity: 0.4
    initial_rf_to_input_ratio: 8.0
    # learning
    newborn_pruning_cycle: 50.0
    newborn_pruning_stages: 20
    newborn_pruning_mode: powerlaw
#    prune_grow_cycle: 200.0
    adapt_to_ff_sparsity: True
    boosting_k: 0.5

    initial_max_rf_sparsity: 0.6
    target_rf_to_input_ratio: 0.3

#    rf_sparsity: 0.6
#    rf_to_input_ratio: 0.3
#    rf_to_input_ratio: 0.8

    # learning
    learning_rate: 0.02
    learning_algo: new
    synaptogenesis_cycle: 200.0

    # output
    output_sds: ???
    output_mode: rate

  _common_base:
    _base_: $_base.spatial_pooler.default
    # input
#    target_rf_to_input_ratio: 0.3
    target_rf_to_input_ratio: 0.5
#    target_rf_to_input_ratio: 0.7
#    target_rf_to_input_ratio: 2.0

    target_max_rf_sparsity: 0.1
    initial_max_rf_sparsity: 0.5
    initial_rf_to_input_ratio: 8.0
    # learning
    learning_rate: 0.01
    newborn_pruning_cycle: 100.0
    newborn_pruning_stages: 20
    newborn_pruning_mode: powerlaw
    prune_grow_cycle: 1000.0
    adapt_to_ff_sparsity: True
    boosting_k: 7.0

setups:
  rate_ann:
    input_mode: rate
    # classifier_symexp_logits: True
    encoding_sds: [125, 1]
  rate_ann_2k:
    input_mode: rate
    encoding_sds: [2000, 1]
  rate_soft_hebb:
    encoder: sp.soft_hebb
    input_mode: rate
    ds_norm: l2
    encoding_sds: [2000, 20]
#    encoding_sds: [800, 8]
  rate_soft_hebb_ext:
    _base_: setups.rate_soft_hebb
    encoder: sp.soft_hebb_ext
    encoding_sds: [2000, 10]
#    encoding_sds: [800, 4]
  rate_krotov:
    encoder: sp.krotov
#    sdr_tracker: False
    input_mode: rate
    encoding_sds: [2000, 7]
#    encoding_sds: [800, 3]
  rate_krotov_adaptive:
    _base_: setups.rate_krotov
    encoder: sp.krotov_adaptive
  rate_se:
    encoder:
      _base_: sp.se
      output_mode: rate
    input_mode: rate
    ds_norm: l1
    encoding_sds: [2000, 25]
#    encoding_sds: [800, 10]
  rate_gse:
    encoder:
      _base_: sp.gse
      output_mode: rate
    input_mode: rate
    ds_norm: lp
#    encoding_sds: [4000, 40]
#    encoding_sds: [2000, 20]
    encoding_sds: [800, 10]
  binary_htm_sparse:
    encoder:
      _base_: sp.htm_sp
      potential_synapses_ratio: 0.05
    input_mode: binary
    encoding_sds: [2000, 40]
  binary_htm_dense:
    encoder:
      _base_: sp.htm_sp
      potential_synapses_ratio: 0.9
    input_mode: binary
    encoding_sds: [2000, 40]
  rate_fl_sp:
    encoder:
      _base_: sp.float_sp
      output_mode: rate
    input_mode: rate
    encoding_sds: [2000, 25]
  binary_sng_sp:
    encoder:
      _base_: sp.float_sp
      output_mode: rate
    input_mode: binary

data: mnist

sdr_tracker:
  _type_: tracker.sdr
  sds: ???

wandb_init:
  _base_: $_base.wandb_init

